# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014, moco_beta
# This file is distributed under the same license as the Redis Documentation (Japanese) package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Redis Documentation (Japanese) 0.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2014-07-31 23:30+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../source/topics/latency.rst:2
# 121094f25f904795a26b969c4309f2ea
msgid "Redis latency problems troubleshooting"
msgstr ""

#: ../../source/topics/latency.rst:4
# 5b42556c9d5d4e7f819f6df92ba0bd3b
msgid "This document will help you understand what the problem could be if you are experiencing latency problems with Redis."
msgstr ""

#: ../../source/topics/latency.rst:7
# c78cb18de190460fbf9dfee0c0e5c5d3
msgid "In this context *latency* is the maximum delay between the time a client issues a command and the time the reply to the command is received by the client. Usually Redis processing time is extremely low, in the sub microsecond range, but there are certain conditions leading to higher latency figures."
msgstr ""

#: ../../source/topics/latency.rst:14
# 7a23516ff17a406fabee51b581fe180d
msgid "Measuring latency"
msgstr ""

#: ../../source/topics/latency.rst:16
# dcf17f98b4c04dc1953a694dd717572a
msgid "If you are experiencing latency problems, probably you know how to measure it in the context of your application, or maybe your latency problem is very evident even macroscopically. However redis-cli can be used to measure the latency of a Redis server in milliseconds, just try:"
msgstr ""

#: ../../source/topics/latency.rst:26
# b84e8a8dfb6046c19ade35f504c38c1b
msgid "Using the internal Redis latency monitoring subsystem"
msgstr ""

#: ../../source/topics/latency.rst:28
# 0ad963e9d3b84bc592a5d96f95495e0f
msgid "Since Redis 2.8.13, Redis provides latency monitoring capabilities that are able to sample differnet execution paths to understand where the server is blocking. This makes debugging of the problems illustarated in this documentation much simpler, so we suggest to enable latency monitoring ASAP. Please refer to the `Latency monitor documentation </topics/latency-monitor>`__."
msgstr ""

#: ../../source/topics/latency.rst:35
# b824e33b660b4526b95681a7922b67d9
msgid "While the latency monitoring sampling and reporting capabilities will make simpler to understand the soruce of latency in your Redis system, it is still advised that you read this documentation extensively to better understand the topic of Redis and latency spikes."
msgstr ""

#: ../../source/topics/latency.rst:41
# fd12d6db49c14d55babd21abea2c980e
msgid "Latency baseline"
msgstr ""

#: ../../source/topics/latency.rst:43
# baac5a39a843416db2f208ba8f6b0476
msgid "There is a kind of latency that is inherently part of the environment where you run Redis, that is the latency provided by your operating system kernel and, if you are using virtualization, by the hypervisor you are using."
msgstr ""

#: ../../source/topics/latency.rst:48
# 4648daed2ce64854800bbc01488f5771
msgid "While this latency can't be removed it is important to study it because it is the baseline, or in other words, you'll not be able to achieve a Redis latency that is better than the latency that every process running in your environment will experience because of the kernel or hypervisor implementation or setup."
msgstr ""

#: ../../source/topics/latency.rst:54
# 8f571c55324f4ca0999f09479151c766
msgid "We call this kind of latency **intrinsic latency**, and ``redis-cli`` starting from Redis version 2.8.7 is able to measure it. This is an example run under Linux 3.11.0 running on an entry level server."
msgstr ""

#: ../../source/topics/latency.rst:58
# 13d0b6deb4074951ac0043d91db7a69b
msgid "Note: the argument ``100`` is the number of seconds the test will be executed. The more time we run the test, the more likely we'll be able to spot latency spikes. 100 seconds is usually appropriate, however you may want to perform a few runs at different times. Please note that the test is CPU intensive and will likely saturate a single core in your system."
msgstr ""

#: ../../source/topics/latency.rst:75
# 53f5e032e101457f97196579d8c1553a
msgid "The intrinsic latency of this system is just 0.115 milliseconds (or 115 microseconds), which is a good news, however keep in mind that the intrinsic latency may change over time depending on the load of the system."
msgstr ""

#: ../../source/topics/latency.rst:80
# 944643cd1b50416c9e185a94be147ec6
msgid "Virtualized environments will not show so good numbers, especially with high load or if there are noisy neighbors. The following is a run on a Linode 4096 instance running Redis and Apache:"
msgstr ""

#: ../../source/topics/latency.rst:95
# 96ed1247a521443ea75f2236b755f4cf
msgid "Here we have an intrinsic latency of 9.7 milliseconds: this means that we can't ask better than that to Redis. However other runs at different times in different virtualization environments with higher load or with noisy neighbors can easily show even worse values. We were able to measured up to 40 milliseconds in systems otherwise apparently running normally."
msgstr ""

#: ../../source/topics/latency.rst:103
# f6166a1044334e18bbee23105c5dfe99
msgid "Latency induced by network and communication"
msgstr ""

#: ../../source/topics/latency.rst:105
# 5a6d939645e04ff890771bd1c08d23d4
msgid "Clients connect to Redis using a TCP/IP connection or a Unix domain connection. The typical latency of a 1 GBits/s network is about 200 us, while the latency with a Unix domain socket can be as low as 30 us. It actually depends on your network and system hardware. On top of the communication itself, the system adds some more latency (due to thread scheduling, CPU caches, NUMA placement, etc ...). System induced latencies are significantly higher on a virtualized environment than on a physical machine."
msgstr ""

#: ../../source/topics/latency.rst:114
# aafa3e4c33c444a89ea140638cdb22b1
msgid "The consequence is even if Redis processes most commands in sub microsecond range, a client performing many roundtrips to the server will have to pay for these network and system related latencies."
msgstr ""

#: ../../source/topics/latency.rst:118
# 26a7bc0e8ccc470b93b07c98892de967
msgid "An efficient client will therefore try to limit the number of roundtrips by pipelining several commands together. This is fully supported by the servers and most clients. Aggregated commands like MSET/MGET can be also used for that purpose. Starting with Redis 2.4, a number of commands also support variadic parameters for all data types."
msgstr ""

#: ../../source/topics/latency.rst:124
# 04d93966a867407cb27c61dda49a77b8
msgid "Here are some guidelines:"
msgstr ""

#: ../../source/topics/latency.rst:126
# 18c36e15a2d5479397155816fe26d8d2
msgid "If you can afford it, prefer a physical machine over a VM to host the server."
msgstr ""

#: ../../source/topics/latency.rst:128
# cda6392a2de046d7b0fe752a1b206433
msgid "Do not systematically connect/disconnect to the server (especially true for web based applications). Keep your connections as long lived as possible."
msgstr ""

#: ../../source/topics/latency.rst:131
# 3d66cb57774f4c7bbf460dca1582ea49
msgid "If your client is on the same host than the server, use Unix domain sockets."
msgstr ""

#: ../../source/topics/latency.rst:133
# 480b0b3dc0984201a4fee746decf076a
msgid "Prefer to use aggregated commands (MSET/MGET), or commands with variadic parameters (if possible) over pipelining."
msgstr ""

#: ../../source/topics/latency.rst:135
# 1b29bd1de95c47648a457a29e513c42b
msgid "Prefer to use pipelining (if possible) over sequence of roundtrips."
msgstr ""

#: ../../source/topics/latency.rst:136
# f85e3e5512474c94a2af970c58575d36
msgid "Redis supports Lua server-side scripting to cover cases that are not suitable for raw pipelining (for instance when the result of a command is an input for the following commands)."
msgstr ""

#: ../../source/topics/latency.rst:140
# d264526520024e2ebd11b0ec150a3f1e
msgid "On Linux, some people can achieve better latencies by playing with process placement (taskset), cgroups, real-time priorities (chrt), NUMA configuration (numactl), or by using a low-latency kernel. Please note vanilla Redis is not really suitable to be bound on a **single** CPU core. Redis can fork background tasks that can be extremely CPU consuming like bgsave or AOF rewrite. These tasks must **never** run on the same core as the main event loop."
msgstr ""

#: ../../source/topics/latency.rst:148
# 71e246118f3e426ebdbc052e890b20dc
msgid "In most situations, these kind of system level optimizations are not needed. Only do them if you require them, and if you are familiar with them."
msgstr ""

#: ../../source/topics/latency.rst:153
# 0e4090e15f854fb6a4208a1e6f77e8c6
msgid "Single threaded nature of Redis"
msgstr ""

#: ../../source/topics/latency.rst:155
# 1fbec73daf5d46b6995e374b4e082b64
msgid "Redis uses a *mostly* single threaded design. This means that a single process serves all the client requests, using a technique called **multiplexing**. This means that Redis can serve a single request in every given moment, so all the requests are served sequentially. This is very similar to how Node.js works as well. However, both products are often not perceived as being slow. This is caused in part by the small about of time to complete a single request, but primarily because these products are designed to not block on system calls, such as reading data from or writing data to a socket."
msgstr ""

#: ../../source/topics/latency.rst:165
# 0af01927013248c5ab576a2abb6632c6
msgid "I said that Redis is *mostly* single threaded since actually from Redis 2.4 we use threads in Redis in order to perform some slow I/O operations in the background, mainly related to disk I/O, but this does not change the fact that Redis serves all the requests using a single thread."
msgstr ""

#: ../../source/topics/latency.rst:171
# bd666ccf217f4560a33bff756e3a19cb
msgid "Latency generated by slow commands"
msgstr ""

#: ../../source/topics/latency.rst:173
# 76471e49061f4fcdba59dd9469b1c578
msgid "A consequence of being single thread is that when a request is slow to serve all the other clients will wait for this request to be served. When executing normal commands, like ``GET`` or ``SET`` or ``LPUSH`` this is not a problem at all since this commands are executed in constant (and very small) time. However there are commands operating on many elements, like ``SORT``, ``LREM``, ``SUNION`` and others. For instance taking the intersection of two big sets can take a considerable amount of time."
msgstr ""

#: ../../source/topics/latency.rst:182
# 4156ce8be12748cd82cf04c97062af3a
msgid "The algorithmic complexity of all commands is documented. A good practice is to systematically check it when using commands you are not familiar with."
msgstr ""

#: ../../source/topics/latency.rst:186
# 083002fa127540b0a9cca871f2a8f167
msgid "If you have latency concerns you should either not use slow commands against values composed of many elements, or you should run a replica using Redis replication where to run all your slow queries."
msgstr ""

#: ../../source/topics/latency.rst:190
# 3f1c5f8616ad40dcb3d7b4148072c84d
msgid "It is possible to monitor slow commands using the Redis `Slow Log feature </commands/slowlog>`__."
msgstr ""

#: ../../source/topics/latency.rst:193
# 662bea31708e428cbcde187cddc04765
msgid "Additionally, you can use your favorite per-process monitoring program (top, htop, prstat, etc ...) to quickly check the CPU consumption of the main Redis process. If it is high while the traffic is not, it is usually a sign that slow commands are used."
msgstr ""

#: ../../source/topics/latency.rst:198
# a2c845e8cf5741469833c5359c6dd43d
msgid "**IMPORTANT NOTE**: a VERY common source of latency generated by the execution of slow commands is the use of the ``KEYS`` command in production environments. ``KEYS``, as documented in the Redis documentation, should only be used for debugging purposes. Since Redis 2.8 a new commands were introduced in order to iterate the key space and other large collections incrementally, please check the ``SCAN``, ``SSCAN``, ``HSCAN`` and ``ZSCAN`` commands for more information."
msgstr ""

#: ../../source/topics/latency.rst:207
# 4412480951f74f69b705aca21c19dd38
msgid "Latency generated by fork"
msgstr ""

#: ../../source/topics/latency.rst:209
# 3365366c6f9e4a44998c2b9ad6851205
msgid "In order to generate the RDB file in background, or to rewrite the Append Only File if AOF persistence is enabled, Redis has to fork background processes. The fork operation (running in the main thread) can induce latency by itself."
msgstr ""

#: ../../source/topics/latency.rst:214
# e7e444f5a39346f4a8f2ff79bb7a5675
msgid "Forking is an expensive operation on most Unix-like systems, since it involves copying a good number of objects linked to the process. This is especially true for the page table associated to the virtual memory mechanism."
msgstr ""

#: ../../source/topics/latency.rst:219
# 53394e73284c41af830c77573b2e5d7f
msgid "For instance on a Linux/AMD64 system, the memory is divided in 4 KB pages. To convert virtual addresses to physical addresses, each process stores a page table (actually represented as a tree) containing at least a pointer per page of the address space of the process. So a large 24 GB Redis instance requires a page table of 24 GB / 4 KB \\* 8 = 48 MB."
msgstr ""

#: ../../source/topics/latency.rst:225
# d9aabc89ac8845ad8a37bd8ec45f672a
msgid "When a background save is performed, this instance will have to be forked, which will involve allocating and copying 48 MB of memory. It takes time and CPU, especially on virtual machines where allocation and initialization of a large memory chunk can be expensive."
msgstr ""

#: ../../source/topics/latency.rst:231
# db51a37460fd49d9841b8a9803572868
msgid "Fork time in different systems"
msgstr ""

#: ../../source/topics/latency.rst:233
# 9a3b6db0b1b34b4aa7ae60791b3ac8a2
msgid "Modern hardware is pretty fast to copy the page table, but Xen is not. The problem with Xen is not virtualization-specific, but Xen-specific. For instance using VMware or Virtual Box does not result into slow fork time. The following is a table that compares fork time for different Redis instance size. Data is obtained performing a BGSAVE and looking at the ``latest_fork_usec`` filed in the ``INFO`` command output."
msgstr ""

#: ../../source/topics/latency.rst:240
# cbc833f9a5d54daba71e832baa1365ec
msgid "**Linux beefy VM on VMware** 6.0GB RSS forked in 77 milliseconds (12.8 milliseconds per GB)."
msgstr ""

#: ../../source/topics/latency.rst:242
# 8c2df0ef1db0402bbd32ab63d02cfaab
msgid "**Linux running on physical machine (Unknown HW)** 6.1GB RSS forked in 80 milliseconds (13.1 milliseconds per GB)"
msgstr ""

#: ../../source/topics/latency.rst:244
# 6ab92101dbe14ea89685495c23c64244
msgid "**Linux running on physical machine (Xeon @ 2.27Ghz)** 6.9GB RSS forked into 62 milliseconds (9 milliseconds per GB)."
msgstr ""

#: ../../source/topics/latency.rst:246
# 8828e78cd4fc4d349c79bf2daebd8385
msgid "**Linux VM on 6sync (KVM)** 360 MB RSS forked in 8.2 milliseconds (23.3 millisecond per GB)."
msgstr ""

#: ../../source/topics/latency.rst:248
# dfa55cdbf3c948ae97425004f3efcaef
msgid "**Linux VM on EC2 (Xen)** 6.1GB RSS forked in 1460 milliseconds (239.3 milliseconds per GB)."
msgstr ""

#: ../../source/topics/latency.rst:250
# 7b5a1503755241d4860c8fbe026298c3
msgid "**Linux VM on Linode (Xen)** 0.9GBRSS forked into 382 millisecodns (424 milliseconds per GB)."
msgstr ""

#: ../../source/topics/latency.rst:253
# 623b6bb760e04a229f9ed6de452ce7a0
msgid "As you can see a VM running on Xen has a performance hit that is between one order to two orders of magnitude. We believe this is a severe problem with Xen and we hope it will be addressed ASAP."
msgstr ""

#: ../../source/topics/latency.rst:258
# 74bbcd5585694bab962b45825083c81b
msgid "Latency induced by swapping (operating system paging)"
msgstr ""

#: ../../source/topics/latency.rst:260
# 624a817b0fc246a98b181ea1d1c88980
msgid "Linux (and many other modern operating systems) is able to relocate memory pages from the memory to the disk, and vice versa, in order to use the system memory efficiently."
msgstr ""

#: ../../source/topics/latency.rst:264
# 5d9d7d599fa9446989ec94a31a402e03
msgid "If a Redis page is moved by the kernel from the memory to the swap file, when the data stored in this memory page is used by Redis (for example accessing a key stored into this memory page) the kernel will stop the Redis process in order to move the page back into the main memory. This is a slow operation involving random I/Os (compared to accessing a page that is already in memory) and will result into anomalous latency experienced by Redis clients."
msgstr ""

#: ../../source/topics/latency.rst:272
# 4769f7469dfa41b284345231aa9745ab
msgid "The kernel relocates Redis memory pages on disk mainly because of three reasons:"
msgstr ""

#: ../../source/topics/latency.rst:275
# 5423391c268b435e927f305704f38ee7
msgid "The system is under memory pressure since the running processes are demanding more physical memory than the amount that is available. The simplest instance of this problem is simply Redis using more memory than the one available."
msgstr ""

#: ../../source/topics/latency.rst:279
# 47c0a1d396d44464beeb5bbbb325460b
msgid "The Redis instance data set, or part of the data set, is mostly completely idle (never accessed by clients), so the kernel could swap idle memory pages on disk. This problem is very rare since even a moderately slow instance will touch all the memory pages often, forcing the kernel to retain all the pages in memory."
msgstr ""

#: ../../source/topics/latency.rst:284
# dba447cee81e4fbcb3bb471fe98cbd04
msgid "Some processes are generating massive read or write I/Os on the system. Because files are generally cached, it tends to put pressure on the kernel to increase the filesystem cache, and therefore generate swapping activity. Please note it includes Redis RDB and/or AOF background threads which can produce large files."
msgstr ""

#: ../../source/topics/latency.rst:290
# 51f3ee2a3fab44e395920bfa8805030c
msgid "Fortunately Linux offers good tools to investigate the problem, so the simplest thing to do is when latency due to swapping is suspected is just to check if this is the case."
msgstr ""

#: ../../source/topics/latency.rst:294
# dbaeb8ba745e4a8180985f6ace9fb64f
msgid "The first thing to do is to checking the amount of Redis memory that is swapped on disk. In order to do so you need to obtain the Redis instance pid:"
msgstr ""

#: ../../source/topics/latency.rst:303
# 049c440b18164f30a725289493421c78
msgid "Now enter the /proc file system directory for this process:"
msgstr ""

#: ../../source/topics/latency.rst:309
# 60b82021c1504717a1de03480008b911
msgid "Here you'll find a file called **smaps** that describes the memory layout of the Redis process (assuming you are using Linux 2.6.16 or newer). This file contains very detailed information about our process memory maps, and one field called **Swap** is exactly what we are looking for. However there is not just a single swap field since the smaps file contains the different memory maps of our Redis process (The memory layout of a process is more complex than a simple linear array of pages)."
msgstr ""

#: ../../source/topics/latency.rst:318
# a9079f5748054ea5a86eb63b62f65e23
msgid "Since we are interested in all the memory swapped by our process the first thing to do is to grep for the Swap field across all the file:"
msgstr ""

#: ../../source/topics/latency.rst:355
# 5728b5f85e8a48e1ad48480231ac82f0
msgid "If everything is 0 kb, or if there are sporadic 4k entries, everything is perfectly normal. Actually in our example instance (the one of a real web site running Redis and serving hundreds of users every second) there are a few entries that show more swapped pages. To investigate if this is a serious problem or not we change our command in order to also print the size of the memory map:"
msgstr ""

#: ../../source/topics/latency.rst:426
# 98df8728724945a99aaba4ced6320e5b
msgid "As you can see from the output, there is a map of 720896 kB (with just 12 kB swapped) and 156 kb more swapped in another map: basically a very small amount of our memory is swapped so this is not going to create any problem at all."
msgstr ""

#: ../../source/topics/latency.rst:431
# d410ceb23f72404a8b9ea1ce1a47f7dc
msgid "If instead a non trivial amount of the process memory is swapped on disk your latency problems are likely related to swapping. If this is the case with your Redis instance you can further verify it using the **vmstat** command:"
msgstr ""

#: ../../source/topics/latency.rst:448
# 4a22fe25e89c4d95b63c488a4ee2e189
msgid "^C"
msgstr ""

#: ../../source/topics/latency.rst:450
# 31df2ae932904b9c968383acbbfca909
msgid "The interesting part of the output for our needs are the two columns **si** and **so**, that counts the amount of memory swapped from/to the swap file. If you see non zero counts in those two columns then there is swapping activity in your system."
msgstr ""

#: ../../source/topics/latency.rst:455
# 8fb1c53456494201a0db728149b6c80d
msgid "Finally, the **iostat** command can be used to check the global I/O activity of the system."
msgstr ""

#: ../../source/topics/latency.rst:468
# 3fc9f9f1990b4d2293a06decaae3c956
msgid "If your latency problem is due to Redis memory being swapped on disk you need to lower the memory pressure in your system, either adding more RAM if Redis is using more memory than the available, or avoiding running other memory hungry processes in the same system."
msgstr ""

#: ../../source/topics/latency.rst:474
# 37b4d9f493ae4787b000e3732dfe4a5b
msgid "Latency due to AOF and disk I/O"
msgstr ""

#: ../../source/topics/latency.rst:476
# bea8f272ebcb47dc9e3054b19cad5e58
msgid "Another source of latency is due to the Append Only File support on Redis. The AOF basically uses two system calls to accomplish its work. One is write(2) that is used in order to write data to the append only file, and the other one is fdatasync(2) that is used in order to flush the kernel file buffer on disk in order to ensure the durability level specified by the user."
msgstr ""

#: ../../source/topics/latency.rst:483
# fc6b43ae46e34b8aa6c1d6fff60ec1b5
msgid "Both the write(2) and fdatasync(2) calls can be source of latency. For instance write(2) can block both when there is a system wide sync in progress, or when the output buffers are full and the kernel requires to flush on disk in order to accept new writes."
msgstr ""

#: ../../source/topics/latency.rst:488
# 4e875a7e81414c18acd2b5c6ea90f9e2
msgid "The fdatasync(2) call is a worse source of latency as with many combinations of kernels and file systems used it can take from a few milliseconds to a few seconds to complete, especially in the case of some other process doing I/O. For this reason when possible Redis does the fdatasync(2) call in a different thread since Redis 2.4."
msgstr ""

#: ../../source/topics/latency.rst:494
# a7ed4b76cbe140e891edd1de82666f34
msgid "We'll see how configuration can affect the amount and source of latency when using the AOF file."
msgstr ""

#: ../../source/topics/latency.rst:497
# f140889cfbe34fa99410cdfbb5279d71
msgid "The AOF can be configured to perform an fsync on disk in three different ways using the **appendfsync** configuration option (this setting can be modified at runtime using the **CONFIG SET** command)."
msgstr ""

#: ../../source/topics/latency.rst:501
# e63a34513bf74ffb856f06566a9b7a07
msgid "When appendfsync is set to the value of **no** Redis performs no fsync. In this configuration the only source of latency can be write(2). When this happens usually there is no solution since simply the disk can't cope with the speed at which Redis is receiving data, however this is uncommon if the disk is not seriously slowed down by other processes doing I/O."
msgstr ""

#: ../../source/topics/latency.rst:508
# 8322879fe2b240d3949a5f93a06c854b
msgid "When appendfsync is set to the value of **everysec** Redis performs an fsync every second. It uses a different thread, and if the fsync is still in progress Redis uses a buffer to delay the write(2) call up to two seconds (since write would block on Linux if an fsync is in progress against the same file). However if the fsync is taking too long Redis will eventually perform the write(2) call even if the fsync is still in progress, and this can be a source of latency."
msgstr ""

#: ../../source/topics/latency.rst:516
# 1a067e0f228f4b8e80456865f84bb56e
msgid "When appendfsync is set to the value of **always** an fsync is performed at every write operation before replying back to the client with an OK code (actually Redis will try to cluster many commands executed at the same time into a single fsync). In this mode performances are very low in general and it is strongly recommended to use a fast disk and a file system implementation that can perform the fsync in short time."
msgstr ""

#: ../../source/topics/latency.rst:524
# 745c521eb87a4c7faf43bbd269e46967
msgid "Most Redis users will use either the **no** or **everysec** setting for the appendfsync configuration directive. The suggestion for minimum latency is to avoid other processes doing I/O in the same system. Using an SSD disk can help as well, but usually even non SSD disks perform well with the append only file if the disk is spare as Redis writes to the append only file without performing any seek."
msgstr ""

#: ../../source/topics/latency.rst:531
# e0dbd08a5ac845ac8257a74c84493be5
msgid "If you want to investigate your latency issues related to the append only file you can use the strace command under Linux:"
msgstr ""

#: ../../source/topics/latency.rst:538
# 08fea033c5db46eebd6cbd58e606c88a
msgid "The above command will show all the fdatasync(2) system calls performed by Redis in the main thread. With the above command you'll not see the fdatasync system calls performed by the background thread when the appendfsync config option is set to **everysec**. In order to do so just add the -f switch to strace."
msgstr ""

#: ../../source/topics/latency.rst:544
# 68b2660dd00245ec830a69dd1dff88f0
msgid "If you wish you can also see both fdatasync and write system calls with the following command:"
msgstr ""

#: ../../source/topics/latency.rst:551
# 72b46a2e0ac54948bc388446c85653ce
msgid "However since write(2) is also used in order to write data to the client sockets this will likely show too many things unrelated to disk I/O. Apparently there is no way to tell strace to just show slow system calls so I use the following command:"
msgstr ""

#: ../../source/topics/latency.rst:561
# bd1f3c0281244a0fb388ff77ef8c07e7
msgid "Latency generated by expires"
msgstr ""

#: ../../source/topics/latency.rst:563
# 2ad52a0e0a994da689360e78b33673a6
msgid "Redis evict expired keys in two ways:"
msgstr ""

#: ../../source/topics/latency.rst:565
# 070b4ee13fa14aa6bac5b8a2f994f3cb
msgid "One *lazy* way expires a key when it is requested by a command, but it is found to be already expired."
msgstr ""

#: ../../source/topics/latency.rst:567
# 0ef4de6f0c4a45e68bb3b5e2e2b6221c
msgid "One *active* way expires a few keys every 100 milliseconds."
msgstr ""

#: ../../source/topics/latency.rst:569
# 9987d3f5a9eb49699f39c2211ab0a2bd
msgid "The active expiring is designed to be adaptive. An expire cycle is started every 100 milliseconds (10 times per second), and will do the following:"
msgstr ""

#: ../../source/topics/latency.rst:573
# 2eb5d721326d466c90294454a696b608
msgid "Sample ``REDIS_EXPIRELOOKUPS_PER_CRON`` keys, evicting all the keys already expired."
msgstr ""

#: ../../source/topics/latency.rst:575
# 517e49801ca0428e82aa83dcb444a796
msgid "If the more than 25% of the keys were found expired, repeat."
msgstr ""

#: ../../source/topics/latency.rst:577
# e5668ee33f6e43fa8a8006849b1c90a5
msgid "Given that ``REDIS_EXPIRELOOKUPS_PER_CRON`` is set to 10 by default, and the process is performed ten times per second, usually just 100 keys per second are actively expired. This is enough to clean the DB fast enough even when already expired keys are not accessed for a long time, so that the *lazy* algorithm does not help. At the same time expiring just 100 keys per second has no effects in the latency a Redis instance."
msgstr ""

#: ../../source/topics/latency.rst:584
# a6850dc9d81f4027ac341484190cc81e
msgid "However the algorithm is adaptive and will loop if it founds more than 25% of keys already expired in the set of sampled keys. But given that we run the algorithm ten times per second, this means that the unlucky event of more than 25% of the keys in our random sample are expiring at least *in the same second*."
msgstr ""

#: ../../source/topics/latency.rst:590
# 4c0236a1dec44b159e9eb1678ba4442a
msgid "Basically this means that **if the database contains has many many keys expiring in the same second, and this keys are at least 25% of the current population of keys with an expire set**, Redis can block in order to reach back a percentage of keys already expired that is less than 25%."
msgstr ""

#: ../../source/topics/latency.rst:596
# e3bf1f183b79467780846a21c2c4a975
msgid "This approach is needed in order to avoid using too much memory for keys that area already expired, and usually is absolutely harmless since it's strange that a big number of keys are going to expire in the same exact second, but it is not impossible that the user used ``EXPIREAT`` extensively with the same Unix time."
msgstr ""

#: ../../source/topics/latency.rst:602
# fcb1c7d3a4e34d21adeb811db89e83a4
msgid "In short: be aware that many keys expiring at the same moment can be a source of latency."
msgstr ""

#: ../../source/topics/latency.rst:606
# 410820550a2a413a86e081a4ce5bedf5
msgid "Redis software watchdog"
msgstr ""

#: ../../source/topics/latency.rst:608
# 1a5d39e17c9a4f24ba447ed8453f7e36
msgid "Redis 2.6 introduces the *Redis Software Watchdog* that is a debugging tool designed to track those latency problems that for one reason or the other esacped an analysis using normal tools."
msgstr ""

#: ../../source/topics/latency.rst:612
# 11ebb5e08ed843058897aaef15dcd3d9
msgid "The software watchdog is an experimental feature. While it is designed to be used in production enviroments care should be taken to backup the database before proceeding as it could possibly have unexpected interactions with the normal execution of the Redis server."
msgstr ""

#: ../../source/topics/latency.rst:617
# 693acf52b96942bc842c78a15df4d4dc
msgid "It is important to use it only as *last resort* when there is no way to track the issue by other means."
msgstr ""

#: ../../source/topics/latency.rst:620
# 6ff0bc100dc14bc082d060779707a262
msgid "This is how this feature works:"
msgstr ""

#: ../../source/topics/latency.rst:622
# 70ecc3c21aed407e82914e4c7a30eb1e
msgid "The user enables the softare watchdog using te ``CONFIG SET`` command."
msgstr ""

#: ../../source/topics/latency.rst:624
# b856b175a8074030bb0b114ed3e44fa1
msgid "Redis starts monitoring itself constantly."
msgstr ""

#: ../../source/topics/latency.rst:625
# 8d26d90dd12545f2a56103052ef05e42
msgid "If Redis detects that the server is blocked into some operation that is not returning fast enough, and that may be the source of the latency issue, a low level report about where the server is blocked is dumped on the log file."
msgstr ""

#: ../../source/topics/latency.rst:629
# 347d9071336749b3a4f1cbb6dbf5e68a
msgid "The user contacts the developers writing a message in the Redis Google Group, including the watchdog report in the message."
msgstr ""

#: ../../source/topics/latency.rst:632
# b4e3a8d8b2dd4220ba48450db7b5c194
msgid "Note that this feature can not be enabled using the redis.conf file, because it is designed to be enabled only in already running instances and only for debugging purposes."
msgstr ""

#: ../../source/topics/latency.rst:636
# 460bf892311249a1b017a1040f21be35
msgid "To enable the feature just use the following:"
msgstr ""

#: ../../source/topics/latency.rst:642
# 7331a040d3ff4cb596f9d4f4d7ed5245
msgid "The period is specified in milliseconds. In the above example I specified to log latency issues only if the server detects a delay of 500 milliseconds or greater. The minimum configurable period is 200 milliseconds."
msgstr ""

#: ../../source/topics/latency.rst:647
# 168b6aa74d0c450ebe855a4b18f8760e
msgid "When you are done with the software watchdog you can turn it off setting the ``watchdog-period`` parameter to 0. **Important:** remember to do this because keeping the instance with the watchdog turned on for a longer time than needed is generally not a good idea."
msgstr ""

#: ../../source/topics/latency.rst:652
# 3077cd33c2d542ae878409ead8ce8db0
msgid "The following is an example of what you'll see printed in the log file once the software watchdog detects a delay longer than the configured one:"
msgstr ""

#: ../../source/topics/latency.rst:676
# 30edb5880e4c4f9b884f8a60447df9f2
msgid "Note: in the example the **DEBUG SLEEP** command was used in order to block the server. The stack trace is different if the server blocks in a different context."
msgstr ""

#: ../../source/topics/latency.rst:680
# 89bb72baa68144bebc9c70ddd9a11e61
msgid "If you happen to collect multiple watchdog stack traces you are encouraged to send everything to the Redis Google Group: the more traces we obtain, the simpler it will be to understand what the problem with your instance is."
msgstr ""

#: ../../source/topics/latency.rst:686
# 1106171981fa407db09a5e5d3bef9156
msgid "APPENDIX A: Experimenting with huge pages"
msgstr ""

#: ../../source/topics/latency.rst:688
# d99fd28aa4294a7ea70f1b9a17e45343
msgid "Latency introduced by fork can be mitigated using huge pages at the cost of a bigger memory usage during persistence. The following appeindex describe in details this feature as implemented in the Linux kernel."
msgstr ""

#: ../../source/topics/latency.rst:692
# bec7927ace0442039d6b2b590dc4c407
msgid "Some CPUs can use different page size though. AMD and Intel CPUs can support 2 MB page size if needed. These pages are nicknamed *huge pages*. Some operating systems can optimize page size in real time, transparently aggregating small pages into huge pages on the fly."
msgstr ""

#: ../../source/topics/latency.rst:697
# aa6ffec156904fe0b9d3b077f51cef53
msgid "On Linux, explicit huge pages management has been introduced in 2.6.16, and implicit transparent huge pages are available starting in 2.6.38. If you run recent Linux distributions (for example RH 6 or derivatives), transparent huge pages can be activated, and you can use a vanilla Redis version with them."
msgstr ""

#: ../../source/topics/latency.rst:703
# bcfc37b00d5548c385a6b2c47b4d21a9
msgid "This is the preferred way to experiment/use with huge pages on Linux."
msgstr ""

#: ../../source/topics/latency.rst:705
# c3d741fb24ed4029b1462920e70e7d28
msgid "Now, if you run older distributions (RH 5, SLES 10-11, or derivatives), and not afraid of a few hacks, Redis requires to be patched in order to support huge pages."
msgstr ""

#: ../../source/topics/latency.rst:709
# de80f12d6034429fb217af5286418c46
msgid "The first step would be to read `Mel Gorman's primer on huge pages <http://lwn.net/Articles/374424/>`__"
msgstr ""

#: ../../source/topics/latency.rst:712
# a4e60b213d924aec9a911b5679cdacfb
msgid "There are currently two ways to patch Redis to support huge pages."
msgstr ""

#: ../../source/topics/latency.rst:714
# 2bb02f3e3f384151952567a9cba68f1d
msgid "For Redis 2.4, the embedded jemalloc allocator must be patched. `patch <https://gist.github.com/1171054>`__ by Pieter Noordhuis. Note this patch relies on the anonymous mmap huge page support, only available starting 2.6.32, so this method cannot be used for older distributions (RH 5, SLES 10, and derivatives)."
msgstr ""

#: ../../source/topics/latency.rst:720
# a5b328d1cb32433d9f90b20111fbead5
msgid "For Redis 2.2, or 2.4 with the libc allocator, Redis makefile must be altered to link Redis with `the libhugetlbfs library <http://libhugetlbfs.sourceforge.net/>`__. It is a straightforward `change <https://gist.github.com/1240452>`__"
msgstr ""

#: ../../source/topics/latency.rst:725
# 82cea63fe01e484bb9019e71679fe21a
msgid "Then, the system must be configured to support huge pages."
msgstr ""

#: ../../source/topics/latency.rst:727
# a1f69c864b3c4ef591c5738eb57c6242
msgid "The following command allocates and makes N huge pages available:"
msgstr ""

#: ../../source/topics/latency.rst:733
# c1e2cf3ffb444daa88a67e6da95bb958
msgid "The following command mounts the huge page filesystem:"
msgstr ""

#: ../../source/topics/latency.rst:739
# 530ffd95b9a9435a832fab72bbb5a821
msgid "In all cases, once Redis is running with huge pages (transparent or not), the following benefits are expected:"
msgstr ""

#: ../../source/topics/latency.rst:742
# 64091742f2984c2b8bf0c28498777d4b
msgid "The latency due to the fork operations is dramatically reduced. This is mostly useful for very large instances, and especially on a VM."
msgstr ""

#: ../../source/topics/latency.rst:744
# a09862d438024e0db73ac430092cffc0
msgid "Redis is faster due to the fact the translation look-aside buffer (TLB) of the CPU is more efficient to cache page table entries (i.e. the hit ratio is better). Do not expect miracle, it is only a few percent gain at most."
msgstr ""

#: ../../source/topics/latency.rst:748
# e92423b9bc364812b218622102a98fea
msgid "Redis memory cannot be swapped out anymore, which is interesting to avoid outstanding latencies due to virtual memory."
msgstr ""

#: ../../source/topics/latency.rst:751
# 31d64db7bfd046a1bba4f5c2004d471d
msgid "Unfortunately, and on top of the extra operational complexity, there is also a significant drawback of running Redis with huge pages. The COW mechanism granularity is the page. With 2 MB pages, the probability a page is modified during a background save operation is 512 times higher than with 4 KB pages. The actual memory required for a background save therefore increases a lot, especially if the write traffic is truly random, with poor locality. With huge pages, using twice the memory while saving is not anymore a theoretical incident. It really happens."
msgstr ""

#: ../../source/topics/latency.rst:760
# 97da6880cb50478394f0451069b79e0e
msgid "The result of a complete benchmark can be found `here <https://gist.github.com/1272254>`__."
msgstr ""

